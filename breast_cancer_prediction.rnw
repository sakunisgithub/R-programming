\documentclass[11pt, a4paper]{article}

\usepackage[top = 1 in, bottom = 1 in, left = 0.6 in, right = 0.6 in ]{geometry}

\usepackage{amsmath, amssymb, amsfonts}
\usepackage{enumerate}
\usepackage{xcolor}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{float}
\usepackage{adjustbox}
\usepackage{dingbat}
\usepackage{skak}
\usepackage{pifont}
\usepackage{bbding}
\usepackage{customdice}

\definecolor{COL1}{HTML}{0719F2}
\definecolor{col2}{HTML}{C900FF}
\definecolor{col3}{HTML}{EB6C0E}
\definecolor{col4}{HTML}{FF00F7}
\definecolor{col5}{HTML}{E7400F}
\definecolor{col6}{HTML}{0FAA0D}
\definecolor{col7}{HTML}{13E10D}
\definecolor{col8}{HTML}{FE091F}
\definecolor{col9}{HTML}{F6470F}
\definecolor{col10}{HTML}{1D08CE}
\definecolor{col11}{HTML}{F8766D}
\definecolor{col12}{HTML}{00BFC4}
\definecolor{col13}{HTML}{B81D90}
\definecolor{col14}{HTML}{0AB1E7}

\pagestyle{fancy}
\lhead{Harnessing \textcolor{col3}{\textbf{Logistic Regression}} for \textcolor{col4}{\textbf{Breast Cancer Prediction}}}
\cfoot{Page \thepage\ of \pageref{LastPage}}



\title{}
\author{}
\date{}

\begin{document}

\maketitle

\tableofcontents

\newpage

<<r, echo = F>>=
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=90),tidy=TRUE)
@

\section{\textcolor{COL1}{Abstract}}

\hspace{1cm} This project delves into the development and evaluation of a logistic regression model for breast cancer prediction. Leveraging a data-set comprising cytological features of Fine Needle Aspirates of patients, logistic regression is employed to predict the likelihood of breast cancer occurrence. \\

\hspace{1cm} The model utilizes variables such as radius, texture, smoothness, compactness, concavity, symmetry and fractal dimension to discern patterns indicative of malignancy.  \\

\hspace{1cm} Model building encompasses several stages: data pre-processing (includes feature selection), model training, and evaluation. \\

\hspace{1cm} The ultimate goal is to construct a reliable predictive tool that aids in early detection and prognosis of breast cancer, thereby contributing to improved patient outcomes and healthcare decision-making. 



\section{\textcolor{COL1}{Assumptions}}

\leftpointright \hspace{0.3cm} Key assumptions for implementing logistic regression are as follows. \\


\dice{1} \hspace{0.2cm} Binary logistic regression requires the dependent/response variable to be \textcolor{col9}{\textbf{dichotomous}} in nature. \\

\dice{2} \hspace{0.2cm} The observations must be \textcolor{col9}{\textbf{independent}} of each other. In other words, the observations should not come from repeated measurements or matched data. \\

\dice{3} \hspace{0.2cm} Logistic regression requires there to be little or \textcolor{col9}{\textbf{no multicollinearity}} among the predictor/explanatory variables. This means that the independent variables must not be too highly correlated with each other. \\

\dice{4} \hspace{0.2cm} Logistic regression assumes \textcolor{col9}{\textbf{linear relationship}} between independent variables and log odds of the dependent variable. \\

\dice{5} \hspace{0.2cm} Logistic regression analysis yields reliable, robust, and valid results when a \textcolor{col9}{\textbf{larger sample size}} of the data-set is considered.



\section{\textcolor{COL1}{Caution}}

\CrossMaltese \hspace{0.2cm} Due to ethical considerations and the limitations of machine learning for medical diagnosis, this model should not be used as a sole tool for breast cancer detection. It can serve as a preliminary screening tool to encourage further medical evaluation.

\newpage
\section{\textcolor{COL1}{Data Collection}}

\hspace{1cm} The data was collected as part of a study conducted by William H. Wolberg, W. Nick Street, O. L. Mangasarian. \\

$\bullet$ \textbf{Fine Needle Aspirates}

\hspace{1cm} A small drop of viscous fluid was aspirated from breast masses by making multiple passes with a 23 gauge needle as negative pressure was applied to an attached syringe. The aspirated material was expressed onto a silane coated glass slide. A similar slide was placed face down on the aspirate, and the aspirate was spread as the slides were separated with a horizontal motion. Preparations were immediately fixed in 95\% ethanol and examined after they were stained with hematoxylin and eosin.

\hspace{1cm} Our database of breast fine needle aspirations (FNA) consists of 569 consecutive breast aspirates that contained epithelial cells (212 with cancer and 357 with fibrocystic disease). Only palpable breast masses were aspirated and only noncystic ones were analysed. All cancers were histologically confirmed and all patients with fibrocystic disease were either biopsied or followed for a year without enlargement of previously aspirated mass. \\

$\bullet$ \textbf{Image Preparation}

\hspace{1cm} The area on the aspirate slides to be analyzed was visually selected for minimal nuclear overlap. The image for digital analysis was generated by a JVC TK-1070U color video camera mounted atop an Olympus microscope and the image was projected into the camera with a 63 x objective and a 2.5 x ocular. The image was captured by a ComputerEyes/RT color framegrabber board (Digital Vision, Inc., Dedham MA 02026) as a 512 x 480, 8-bit-per-pixel Targa file. The resulting image was stored in memory as a 2-dimensional array, with each picture element (pixel) having a value between 0 and 255 representing the light intensity at that point. \\

The following is an image after proper demarcation of the cell nuclei. \\

\begin{figure}[!htbp]
\centering
\includegraphics[scale = 1]{microscope_image}
\end{figure}


\newpage
\section{\textcolor{COL1}{Data Description}}

\hspace{1cm} The computer vision diagnostic system extracts ten nuclear features from the isolated cell nuclei. All of the features are numerically modeled such that larger values indicate a higher likelihood of malignancy. The mean value, worst (mean of the three largest values), and standard error of each feature were computed for each image, resulting in a total of \textbf{\textit{thirty}} features for each case in the study along with the response variable \textbf{\textit{\textcolor{blue}{diagnosis}}}. The value of a feature for an image is the mean of the values for the individual nucleus. \\

The extracted features are as follows : \\

\FiveStarShadow \hspace{1pt} \textbf{\textit{\textcolor{blue}{Radius}}}

\hspace{1cm} The radius of an individual nucleus is measured by averaging the length of the radial line segments joining the center and the individual perimeter points.

\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{radius}
\end{figure}

\FiveStarShadow \hspace{1pt} \textbf{\textit{\textcolor{blue}{Perimeter}}}

\hspace{1cm} The total distance between consecutive perimeter points constitutes the nuclear perimeter. \\

\FiveStarShadow \hspace{1pt} \textbf{\textit{\textcolor{blue}{Area}}}

\hspace{1cm} Nuclear area is measured simply by counting the number of pixels on the interior of the perimeter and adding one-half of the pixels on the perimeter. \\

\FiveStarShadow \hspace{1pt} \textbf{\textit{\textcolor{blue}{Compactness}}}

\hspace{1cm} Perimeter and area are combined to give a measure of the compactness of the cell nuclei using the formula $\text{perimeter}^2 / \text{area}$. This dimensionless number is at a minimum with a circular disk and increases with the irregularity of the boundary. However, this measure of shape also increases for elongated cell nuclei, which do not necessarily indicate an increased likelihood of malignancy. \\

\FiveStarShadow \hspace{1pt} \textbf{\textit{\textcolor{blue}{Smoothness}}}

\hspace{1cm} The smoothness of a nuclear contour is quantified by measuring the difference between the length of a radial line and the mean length of the lines surrounding it. 

\newpage

\FiveStarShadow \hspace{1pt} \textbf{\textit{\textcolor{blue}{Concavity}}}

\hspace{1cm} In a further attempt to capture shape information, the severity of concavities or indentations in a cell nucleus is measured. Chords between non-adjacent perimeter points are drawn and the extent to which the actual boundary of the nucleus lies on the inside of each chord is measured. This feature is greatly affected by the length of these chords, as smaller chords better capture small concavities. It has been chosen to emphasize small indentations, as larger shape irregularities are captured by other features.

\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{concavity}
\end{figure}

\FiveStarShadow \hspace{1pt} \textbf{\textit{\textcolor{blue}{Concave Points}}}

\hspace{1cm} This feature is similar to Concavity but measures only the number, rather than the magnitude of contour concavities. \\

\FiveStarShadow \hspace{1pt} \textbf{\textit{\textcolor{blue}{Symmetry}}}

\hspace{1cm} In order to measure symmetry, the major axis, or longest chord through the center, is found. Then the length difference between lines perpendicular to the major axis to the nuclear boundary in both directions are measured. Special care is taken to account for cases where the major axis cuts the boundary because of a concavity. \\

\FiveStarShadow \hspace{1pt} \textbf{\textit{\textcolor{blue}{Fractal Dimension}}}

\hspace{1cm} The fractal dimension of a nuclear boundary is approximated using the ``coastline approximation" described by Mandelbrot. The perimeter of the nucleus is measured using increasingly larger ``rulers". As the ruler size increases, decreasing the precision of the measurement, the observed perimeter decreases. Plotting log of observed perimeter against log of ruler size and measuring the downward slope gives (the negative of) an approximation to the fractal dimension.

\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{fractal_dimension}
\end{figure}

\FiveStarShadow \hspace{1pt} \textbf{\textit{\textcolor{blue}{Texture}}}

\hspace{1cm} The texture of the cell nucleus is measured by finding the variance of the gray scale intensities in the component pixels.

% \newpage
% \section{\textcolor{COL1}{Necessary Packages}}

<<message=FALSE, echo=FALSE>>=
library(tidyverse)
library(ggthemes)
library(ggcorrplot)
library(GGally)
library(glue)
library(car)
library(ggbeeswarm)
@

\newpage
\section{\textcolor{COL1}{Data-preprocessing}}

\subsection{\textcolor{col2}{Loading the data}}

<<size = "scriptsize">>=
git_path <- "https://raw.githubusercontent.com/sakunisgithub/data_sets/master/WDBC/wisconsin_diagnostic_breast_cancer_data.csv"
wdbc_data <- read.csv(git_path)
@

\subsection{\textcolor{col2}{Initial Sanity Checks}}

\subsubsection{\textcolor{col5}{Data Dimension}}
<<>>=
dim(wdbc_data)
@

\subsubsection{\textcolor{col5}{Variable Names}}
<<>>=
names(wdbc_data)
@

\subsubsection{\textcolor{col5}{Missing Values}}
<<>>=
which(is.na(wdbc_data))
@

\ArrowBoldDownRight \hspace{0.3cm} So we are ensured that there is \textcolor{col6}{\textbf{no missing value}} in the data. \\

\subsection{\textcolor{col2}{Encoding}}
We encode \textbf{\textit{\textcolor{col7}{Malignant}}} as \textbf{1} and \textbf{\textit{\textcolor{col8}{Benign}}} as \textbf{0}.

<<>>=
wdbc_data$diagnosis <- ifelse(wdbc_data$diagnosis == "M", "Malignant", "Benign")
diagnosis_encoded <- ifelse(wdbc_data$diagnosis == "Malignant", 1, 0)
@

$\bullet$ We add a new column \textbf{\textit{\textcolor{blue}{diagnosis\_encoded}}} to the data-set.
<<>>=
wdbc_data_encoded <- data.frame(wdbc_data[,1:2], diagnosis_encoded, wdbc_data[,3:32])
@

$\bullet$ \textbf{\textit{\textcolor{blue}{diagnosis}}} must be a factor.
<<>>==
wdbc_data_encoded$diagnosis <- as.factor(wdbc_data_encoded$diagnosis)
@

\subsection{\textcolor{col2}{Data Summary}}
<<>>=
summary(wdbc_data_encoded)
@

\subsection{\textcolor{col2}{Train-Test Split}}
We split the whole data-set into \textbf{\textit{Training Set}} and \textbf{\textit{Test Set}} by a ratio of 80:20. The \textbf{\textit{Training Set}} is created by choosing 455 rows randomly from the main data-set.
<<>>=
set.seed(runif(1, 1, 10))
a <- sample(nrow(wdbc_data_encoded), nrow(wdbc_data_encoded) * 0.8)
@

<<>>==
train <- wdbc_data_encoded[a,]
dim(train)
@

<<>>==
test <- wdbc_data_encoded[-a,]
dim(test)
@

\newpage

\subsubsection{\textcolor{col5}{Composition of the Response Variable in the \textbf{\textit{Training Set}}}}

<<tidy=FALSE, highlight=TRUE, fig.show='hide'>>=
train %>%
  ggplot(aes(x = diagnosis, fill = diagnosis)) +
  geom_bar(width = 0.5) +
  scale_fill_manual(values = c("#03CD00", "#EA1212")) +
  theme_economist() +
  labs(x = "Diagnosis", y = "", title = "Barplot for the Training Set")
@

<<echo=FALSE>>=
ggsave(path = "D:\\Users\\Documents\\sem_6_project\\project_rnw",
       width = 7,
       height = 7,
       device='png',
       dpi=500,
       filename = "train_barplot.png",
       units = "in")
@

\begin{figure}[!htbp]
\centering
\includegraphics[scale = 1]{train_barplot}
\end{figure}


\newpage

\subsection{\textcolor{col2}{Feature Selection}}

\subsubsection{\textcolor{col5}{Scrutiny of Correlation Matrix}}

One of the most important assumptions of Logistic Regression model is that the independent variables should \textbf{not} be too highly correlated with each other. To ensure that, we need a thorough scrutiny of the correlation matrix of the independent variables.

<<echo=FALSE>>=
cor_train_data <- cor(train[,4:33])
@

<<echo=FALSE, fig.show='hide'>>=
ggcorrplot(cor_train_data,
    method = "square",
    type = "lower",
    lab = TRUE,
    lab_col = "black",
    lab_size = 5,
    outline.color = "white",
    tl.cex = 20,
    legend.title = "") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        panel.background = element_rect(fill = "white"),
        panel.grid.major = element_blank(),
        panel.border = element_blank(),
        legend.key.height = unit(7, 'cm'),
        legend.key.width = unit(1, 'cm'))
@

<<echo=FALSE>>=
ggsave(path = "D:\\Users\\Documents\\sem_6_project\\project_rnw",
       width = 20,
       height = 20,
       device='png',
       dpi=500,
       filename = "cor_mat_train.png",
       units = "in",
       bg = "white")
@


\vspace{0.5cm}

\begin{figure}[!h]
  \centering
  \includegraphics[scale = 0.38]{cor_mat_train}
\end{figure}

\newpage

\smallpencil \hspace{0.5cm} Key takeaways from the \textbf{\textcolor{col5}{correlation matrix}} are as follows :
\begin{enumerate}[(1)]
\item 
  \begin{enumerate}[(i)]
\item \textbf{\textit{\textcolor{blue}{radius\_mean}}}, \textbf{\textit{\textcolor{blue}{perimeter\_mean}}}, \textbf{\textit{\textcolor{blue}{area\_mean}}} are \textcolor{red}{highly correlated} within themselves; the correlations being $\geq$ \Sexpr{round(min(cor_train_data[1, 3], cor_train_data[1, 4], cor_train_data[3, 4]), digits = 2)}.

\item \textbf{\textit{\textcolor{blue}{radius\_se}}}, \textbf{\textit{\textcolor{blue}{perimeter\_se}}}, \textbf{\textit{\textcolor{blue}{area\_se}}} are \textcolor{red}{highly correlated} within themselves; the correlations being $\geq$ \Sexpr{round(min(cor_train_data[11, 13], cor_train_data[11, 14], cor_train_data[13, 14]), digits = 2)}.

\item \textbf{\textit{\textcolor{blue}{radius\_worst}}}, \textbf{\textit{\textcolor{blue}{perimeter\_worst}}}, \textbf{\textit{\textcolor{blue}{area\_worst}}} are \textcolor{red}{highly correlated} within themselves; the correlations being $\geq$ \Sexpr{round(min(cor_train_data[21, 23], cor_train_data[21, 24], cor_train_data[23, 24]), digits = 2)}.

  \end{enumerate}

\item
  \begin{enumerate}[(i)]
\item \textbf{\textit{\textcolor{blue}{compactness\_mean}}}, \textbf{\textit{\textcolor{blue}{concavity\_mean}}}, \textbf{\textit{\textcolor{blue}{concave.points\_mean}}} are \textcolor{red}{highly correlated} within themselves; the correlations being $\geq$ \Sexpr{round(min(cor_train_data[6, 7], cor_train_data[6, 8], cor_train_data[7, 8]), digits = 2)}.

\item \textbf{\textit{\textcolor{blue}{compactness\_se}}}, \textbf{\textit{\textcolor{blue}{concavity\_se}}}, \textbf{\textit{\textcolor{blue}{concave.points\_se}}} are \textcolor{red}{highly correlated} within themselves; the correlations being $\geq$ \Sexpr{round(min(cor_train_data[16, 17], cor_train_data[16, 18], cor_train_data[17, 18]), digits = 2)}.

\item \textbf{\textit{\textcolor{blue}{compactness\_worst}}}, \textbf{\textit{\textcolor{blue}{concavity\_worst}}}, \textbf{\textit{\textcolor{blue}{concave.points\_worst}}} are \textcolor{red}{highly correlated} within themselves; the correlations being $\geq$ \Sexpr{round(min(cor_train_data[26, 27], cor_train_data[26, 28], cor_train_data[27, 28]), digits = 2)}.

  \end{enumerate}

\item The variables giving the \textit{\textbf{mean}} measurements are \textcolor{red}{highly correlated} with the corresponding variables giving \textit{\textbf{worst}} measurements; the correlations ranging from \Sexpr{round(min(diag((cor_train_data[1:10, 21:30]))), digits = 2)} to \Sexpr{round(max(diag((cor_train_data[1:10, 21:30]))), digits = 2)} (rightly so, as higher values of a variable push the mean of the variable higher).

\end{enumerate}


\newpage

\subsubsection{\textcolor{col5}{Exploring the Scatterplot Matrix}}

The following is a scatterplot matrix of the 10 \textbf{\textit{mean}} variables. We shall scan the scatter-plots and the Kernel Density Estimate (KDE) plots for any interesting pattern.

\vspace{0.5cm}

\ding{228} \textcolor{col10}{\textbf{Lesser the overlap of KDE of}} \textcolor{col11}{\textbf{Benign}} \textcolor{col10}{\textbf{and}} \textcolor{col12}{\textbf{Malignant}}, \textcolor{col10}{\textbf{better the variable as a predictor.}} \\

<<echo=FALSE, fig.show='hide'>>=
ggpairs(train,
        columns = 4:13,
        aes(color = diagnosis, alpha = 0.5),
        upper = list(continuous = "points"), legend = c(1,1)) +
        scale_alpha(guide = "none") +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
@

<<echo=FALSE>>=
ggsave(path = "D:\\Users\\Documents\\sem_6_project\\project_rnw",
       width = 19,
       height = 18,
       device='png',
       dpi=500,
       filename = "mean_scatterplot_matrix_train.png",
       units = "in")
@


\vspace{0.5cm}

\begin{figure}[!h]
  \centering
  \includegraphics[scale = 0.4]{mean_scatterplot_matrix_train}
\end{figure}

\newpage

\smallpencil \hspace{0.5cm} Key takeaways from the \textbf{\textcolor{col5}{scatterplot matrix}} are as follows :

\begin{enumerate}[(1)]
\item There is an almost perfect \textcolor{red}{linear relationship} between \textbf{\textit{\textcolor{blue}{radius\_mean}}} and \textbf{\textit{\textcolor{blue}{perimeter\_mean}}}.

\item A \textcolor{red}{non-linear relation} between \textbf{\textit{\textcolor{blue}{radius\_mean}}} and \textbf{\textit{\textcolor{blue}{area\_mean}}} is evident.

\item \textbf{\textit{\textcolor{blue}{perimeter\_mean}}} and \textbf{\textit{\textcolor{blue}{area\_mean}}} also show a \textcolor{red}{strong non-linear relationship}.

\item Scatterplot of \textbf{\textit{\textcolor{blue}{concavity\_mean}}} and \textbf{\textit{\textcolor{blue}{compactness\_mean}}} woos a \textcolor{red}{linear relationship} between them.

\item A \textcolor{red}{hefty linear relationship} is clear from the scatterplot of \textbf{\textit{\textcolor{blue}{concave.points\_mean}}} and \textbf{\textit{\textcolor{blue}{concavity\_mean}}}.

\end{enumerate}

\vspace{1cm}

$\bullet$ A quick go-through of the KDEs available along the principle diagonal of the scatterplot matrix reveals that except for \textbf{\textit{\textcolor{blue}{fractal\_dimension\_mean}}}, KDEs of \textcolor{col12}{\textbf{Malignant}} are always shifted to the right of KDEs of \textcolor{col11}{\textbf{Benign}}; implying larger values of the variables tend to malignancy.

\subsubsection{\textcolor{red}{Data Reduction - Phase 1}}

\begin{enumerate}[(1)]
\item We have seen that \textbf{\textit{\textcolor{blue}{radius\_mean}}}, \textbf{\textit{\textcolor{blue}{perimeter\_mean}}} and \textbf{\textit{\textcolor{blue}{area\_mean}}} are highly correlated among themselves. If we assume the shape of a nucleus roughly as a circle, then \textbf{\textit{\textcolor{blue}{radius\_mean}}} stands to be the most elementary measurement of shape of the nucleus. So we keep \textbf{\textit{\textcolor{blue}{radius\_mean}}} and drop the other two from our data-set. \\

\hspace{1cm} For the same reason, we keep \textbf{\textit{\textcolor{blue}{radius\_se}}}, \textbf{\textit{\textcolor{blue}{radius\_worst}}} only and drop \textbf{\textit{\textcolor{blue}{perimeter\_se}}}, \textbf{\textit{\textcolor{blue}{area\_se}}}, \textbf{\textit{\textcolor{blue}{perimeter\_worst}}}, \textbf{\textit{\textcolor{blue}{area\_worst}}}. \\


\item \textbf{\textit{\textcolor{blue}{compactness\_mean}}},  \textbf{\textit{\textcolor{blue}{concave.points\_mean}}}, \textbf{\textit{\textcolor{blue}{compactness\_se}}},  \textbf{\textit{\textcolor{blue}{concave.points\_se}}}, \textbf{\textit{\textcolor{blue}{compactness\_worst}}},  \textbf{\textit{\textcolor{blue}{concave.points\_worst}}} are also dropped.

\item \textbf{\textit{\textcolor{blue}{id}}} and \textbf{\textit{\textcolor{blue}{diagnosis}}} are also removed as they are no longer of any use.

\end{enumerate}

<<echo=FALSE, highlight=TRUE>>=
train <- subset(train, select = -c(id,
                                   diagnosis,
                                   perimeter_mean,
                                   area_mean,
                                   perimeter_se,
                                   area_se,
                                   compactness_mean,
                                   compactness_se,
                                   concave.points_mean,
                                   concave.points_se,
                                   perimeter_worst,
                                   area_worst,
                                   compactness_worst,
                                   concave.points_worst))
@

We also adjust the \textbf{\textit{Test Set}} accordingly.

<<echo=FALSE, highlight=TRUE>>=
test <- subset(test, select = -c(id,
                                 diagnosis,
                                 perimeter_mean, 
                                 area_mean, 
                                 perimeter_se, 
                                 area_se, 
                                 compactness_mean, 
                                 compactness_se, 
                                 concave.points_mean, 
                                 concave.points_se, 
                                 perimeter_worst, 
                                 area_worst, 
                                 compactness_worst, 
                                 concave.points_worst))
@




\subsubsection{\textcolor{col5}{Validating the Linearity Assumption}}

Another key assumption in logistic regression is \textcolor{col9}{\textbf{linear relationship}} between independent variables and log odds of the dependent variable. \\

Here is how we can visually check for linearity of one numeric variable at a time.

\begin{enumerate}[(1)]
\item Divide the numeric variable (say $X$) into 4 groups as follows -
  \begin{enumerate}[(i)]
  \item \textbf{Group 1} consisting of values of $X$ that are $<$ $Q_1$;
  \item \textbf{Group 2} consisting of values of $X$ that are $\geq$ $Q_1$ and $<$ $Q_2$;
  \item \textbf{Group 3} consisting of values of $X$ that are $\geq$ $Q_2$ and $<$ $Q_3$;
  \item \textbf{Group 4} consisting of values of $X$ that are $\geq$ $Q_3$;
  \end{enumerate}
  
  where $Q_1$, $Q_2$, $Q_3$ are quartiles of $X$.

\newpage

\item Calculate the number of \textcolor{col12}{\textbf{Malignant}} cases in each of the 4 groups and obtain $$ \hat{p_i} = \dfrac{\text{Number of \textcolor{col12}{\textbf{Malignant}} cases in Group} \,\, i}{\text{Total number of values in Group} \,\, i} \,\, \forall \, i=1(1)4.$$

\item Evaluate log odds as $l_i = ln\left( \dfrac{\hat{p_i}}{1 - \hat{p_i}} \right)$, $\forall \, i=1(1)4$.

\item Obtain the medians of the 4 groups. Let $m_1$, $m_2$, $m_3$, $m_4$ be the medians of the groups respectively.

\item Plot the points $(m_1 \, , l_1)$, $(m_2 \, , l_2)$, $(m_3 \, , l_3)$ and $(m_4 \, , l_4)$. Then join the four points by line segments.
\end{enumerate}

$\blacklozenge$ \textcolor{col10}{\textbf{If the relationship is linear, the 4 points will fall approximately on a line.}} \\


The following function takes \textcolor{magenta}{\textit{data-set}} and \textcolor{magenta}{\textit{a numeric variable}} as inputs and returns a line graph.

<<tidy=FALSE, highlight=TRUE, fig.show='hide', message=FALSE>>=
linearity_check <- function(data_set, variable_name){
  
  values <- data_set[variable_name][,1]

  q <- quantile(values)
  g1 <- data_set$diagnosis_encoded[which(values < q[2])]
  g2 <- data_set$diagnosis_encoded[which(values >= q[2] & values < q[3])]
  g3 <- data_set$diagnosis_encoded[which(values >= q[3] & values < q[4])]
  g4 <- data_set$diagnosis_encoded[which(values >= q[4])]

  probs <- c()
  probs[1] <- sum(g1) / length(g1)
  probs[2] <- sum(g2) / length(g2)
  probs[3] <- sum(g3) / length(g3)
  probs[4] <- sum(g4) / length(g4)

  log_odds <- log(probs / (1 - probs))

  med_1 <- median(values[which(values < q[2])])
  med_2 <- median(values[which(values >= q[2] & values < q[3])])
  med_3 <- median(values[which(values >= q[3] & values < q[4])])
  med_4 <- median(values[which(values >= q[4])])

  medians <- c(med_1, med_2, med_3, med_4)

  temp_df <- data.frame(group_medians = medians, logodds = log_odds)

  library(tidyverse)
  
  line_graph <- temp_df %>%
      ggplot(aes(x = group_medians, y = logodds)) +
      geom_line(col = "blue", linewidth = 1, linetype = "twodash") +
      geom_point(size = 3, col = "#F30000") +
      labs(x = variable_name, y = "Log Odds")

  return(line_graph)
}
@


\newpage

Doing the linearity check on multiple training sets will help us to draw more robust and reliable conclusions. So we create 5 more training sets.

<<>>=
training_sets <- list(train)
test_sets <- list(test)

for (i in 1:5) {
  set.seed(runif(1, 1, 10))
  a <- sample(nrow(wdbc_data_encoded), nrow(wdbc_data_encoded) * 0.8)
  train_temp <- wdbc_data_encoded[a,]
  test_temp <- wdbc_data_encoded[-a,]

  training_sets[[i+1]] <- train_temp
  test_sets[[i+1]] <- test_temp
}
@


Now we shall run the function \textcolor{green}{\textit{\textbf{linearity\_check()}}} for different numeric variables for 6 different training sets.

<<echo=FALSE, fig.show='hide'>>=
for (i in 1:6) {
  lc_radius_mean <- linearity_check(data_set = training_sets[[i]],
                                    variable_name = "radius_mean")
  
  mypath <- "D:\\Users\\Documents\\sem_6_project\\project_rnw"
  
  ggsave(plot = lc_radius_mean,
        path = mypath,
        width = 6,
        height = 6,
        device='png',
        dpi=500,
        filename = glue("lc_radius_mean_{i}.png"),
        units = "in",
        bg = "white")
}
@

\newpage

\begin{table}[H]
\caption*{Linearity Check for \textcolor{blue}{\textbf{\textit{radius\_mean}}}}
\begin{center}
\begin{tabular}{cc}
\includegraphics[scale = 0.5]{lc_radius_mean_1} & \includegraphics[scale = 0.5]{lc_radius_mean_2} \\

\includegraphics[scale = 0.5]{lc_radius_mean_3} & \includegraphics[scale = 0.5]{lc_radius_mean_4} \\

\includegraphics[scale = 0.5]{lc_radius_mean_5} & \includegraphics[scale = 0.5]{lc_radius_mean_6}
\end{tabular}
\end{center}
\end{table}




<<echo=FALSE, fig.show='hide'>>=
for (i in 1:6) {
  lc_texture_mean <- linearity_check(data_set = training_sets[[i]],
                                    variable_name = "texture_mean")
  
  mypath <- "D:\\Users\\Documents\\sem_6_project\\project_rnw"
  
  ggsave(plot = lc_texture_mean,
        path = mypath,
        width = 6,
        height = 6,
        device='png',
        dpi=500,
        filename = glue("lc_texture_mean_{i}.png"),
        units = "in",
        bg = "white")
}
@
\newpage
\begin{table}[H]
\caption*{Linearity Check for \textcolor{blue}{\textbf{\textit{texture\_mean}}}}
\begin{center}
\begin{tabular}{cc}
\includegraphics[scale = 0.5]{lc_texture_mean_1} & \includegraphics[scale = 0.5]{lc_texture_mean_2} \\

\includegraphics[scale = 0.5]{lc_texture_mean_3} & \includegraphics[scale = 0.5]{lc_texture_mean_4} \\

\includegraphics[scale = 0.5]{lc_texture_mean_5} & \includegraphics[scale = 0.5]{lc_texture_mean_6}
\end{tabular}
\end{center}
\end{table}




<<echo=FALSE, fig.show='hide'>>=
for (i in 1:6) {
  lc_smoothness_mean <- linearity_check(data_set = training_sets[[i]],
                                    variable_name = "smoothness_mean")
  
  mypath <- "D:\\Users\\Documents\\sem_6_project\\project_rnw"
  
  ggsave(plot = lc_smoothness_mean,
        path = mypath,
        width = 6,
        height = 6,
        device='png',
        dpi=500,
        filename = glue("lc_smoothness_mean_{i}.png"),
        units = "in",
        bg = "white")
}
@
\newpage
\begin{table}[H]
\caption*{Linearity Check for \textcolor{blue}{\textbf{\textit{smoothness\_mean}}}}
\begin{center}
\begin{tabular}{cc}
\includegraphics[scale = 0.5]{lc_smoothness_mean_1} & \includegraphics[scale = 0.5]{lc_smoothness_mean_2} \\

\includegraphics[scale = 0.5]{lc_smoothness_mean_3} & \includegraphics[scale = 0.5]{lc_smoothness_mean_4} \\

\includegraphics[scale = 0.5]{lc_smoothness_mean_5} & \includegraphics[scale = 0.5]{lc_smoothness_mean_6}
\end{tabular}
\end{center}
\end{table}




<<echo=FALSE, fig.show='hide'>>=
for (i in 1:6) {
  lc_concavity_mean <- linearity_check(data_set = training_sets[[i]],
                                    variable_name = "concavity_mean")
  
  mypath <- "D:\\Users\\Documents\\sem_6_project\\project_rnw"
  
  ggsave(plot = lc_concavity_mean,
        path = mypath,
        width = 6,
        height = 6,
        device='png',
        dpi=500,
        filename = glue("lc_concavity_mean_{i}.png"),
        units = "in",
        bg = "white")
}
@
\newpage
\begin{table}[H]
\caption*{Linearity Check for \textcolor{blue}{\textbf{\textit{concavity\_mean}}}}
\begin{center}
\begin{tabular}{cc}
\includegraphics[scale = 0.5]{lc_concavity_mean_1} & \includegraphics[scale = 0.5]{lc_concavity_mean_2} \\

\includegraphics[scale = 0.5]{lc_concavity_mean_3} & \includegraphics[scale = 0.5]{lc_concavity_mean_4} \\

\includegraphics[scale = 0.5]{lc_concavity_mean_5} & \includegraphics[scale = 0.5]{lc_concavity_mean_6}
\end{tabular}
\end{center}
\end{table}




<<echo=FALSE, fig.show='hide'>>=
for (i in 1:6) {
  lc_symmetry_mean <- linearity_check(data_set = training_sets[[i]],
                                    variable_name = "symmetry_mean")
  
  mypath <- "D:\\Users\\Documents\\sem_6_project\\project_rnw"
  
  ggsave(plot = lc_symmetry_mean,
        path = mypath,
        width = 6,
        height = 6,
        device='png',
        dpi=500,
        filename = glue("lc_symmetry_mean_{i}.png"),
        units = "in",
        bg = "white")
}
@
\newpage
\begin{table}[H]
\caption*{Linearity Check for \textcolor{blue}{\textbf{\textit{symmetry\_mean}}}}
\begin{center}
\begin{tabular}{cc}
\includegraphics[scale = 0.5]{lc_symmetry_mean_1} & \includegraphics[scale = 0.5]{lc_symmetry_mean_2} \\

\includegraphics[scale = 0.5]{lc_symmetry_mean_3} & \includegraphics[scale = 0.5]{lc_symmetry_mean_4} \\

\includegraphics[scale = 0.5]{lc_symmetry_mean_5} & \includegraphics[scale = 0.5]{lc_symmetry_mean_6}
\end{tabular}
\end{center}
\end{table}




<<echo=FALSE, fig.show='hide'>>=
for (i in 1:6) {
  lc_fractal_dimension_mean <- linearity_check(data_set = training_sets[[i]],
                                    variable_name = "fractal_dimension_mean")
  
  mypath <- "D:\\Users\\Documents\\sem_6_project\\project_rnw"
  
  ggsave(plot = lc_fractal_dimension_mean,
        path = mypath,
        width = 6,
        height = 6,
        device='png',
        dpi=500,
        filename = glue("lc_fractal_dimension_mean_{i}.png"),
        units = "in",
        bg = "white")
}
@
\newpage
\begin{table}[H]
\caption*{Linearity Check for \textcolor{blue}{\textbf{\textit{fractal\_dimension\_mean}}}}
\begin{center}
\begin{tabular}{cc}
\includegraphics[scale = 0.5]{lc_fractal_dimension_mean_1} & \includegraphics[scale = 0.5]{lc_fractal_dimension_mean_2} \\

\includegraphics[scale = 0.5]{lc_fractal_dimension_mean_3} & \includegraphics[scale = 0.5]{lc_fractal_dimension_mean_4} \\

\includegraphics[scale = 0.5]{lc_fractal_dimension_mean_5} & \includegraphics[scale = 0.5]{lc_fractal_dimension_mean_6}
\end{tabular}
\end{center}
\end{table}




<<echo=FALSE, fig.show='hide'>>=
for (i in 1:6) {
  lc_radius_se <- linearity_check(data_set = training_sets[[i]],
                                    variable_name = "radius_se")
  
  mypath <- "D:\\Users\\Documents\\sem_6_project\\project_rnw"
  
  ggsave(plot = lc_radius_se,
        path = mypath,
        width = 6,
        height = 6,
        device='png',
        dpi=500,
        filename = glue("lc_radius_se_{i}.png"),
        units = "in",
        bg = "white")
}
@
\newpage
\begin{table}[H]
\caption*{Linearity Check for \textcolor{blue}{\textbf{\textit{radius\_se}}}}
\begin{center}
\begin{tabular}{cc}
\includegraphics[scale = 0.5]{lc_radius_se_1} & \includegraphics[scale = 0.5]{lc_radius_se_2} \\

\includegraphics[scale = 0.5]{lc_radius_se_3} & \includegraphics[scale = 0.5]{lc_radius_se_4} \\

\includegraphics[scale = 0.5]{lc_radius_se_5} & \includegraphics[scale = 0.5]{lc_radius_se_6}
\end{tabular}
\end{center}
\end{table}




<<echo=FALSE, fig.show='hide'>>=
for (i in 1:6) {
  lc_texture_se <- linearity_check(data_set = training_sets[[i]],
                                    variable_name = "texture_se")
  
  mypath <- "D:\\Users\\Documents\\sem_6_project\\project_rnw"
  
  ggsave(plot = lc_texture_se,
        path = mypath,
        width = 6,
        height = 6,
        device='png',
        dpi=500,
        filename = glue("lc_texture_se_{i}.png"),
        units = "in",
        bg = "white")
}
@
\newpage
\begin{table}[H]
\caption*{Linearity Check for \textcolor{blue}{\textbf{\textit{texture\_se}}}}
\begin{center}
\begin{tabular}{cc}
\includegraphics[scale = 0.5]{lc_texture_se_1} & \includegraphics[scale = 0.5]{lc_texture_se_2} \\

\includegraphics[scale = 0.5]{lc_texture_se_3} & \includegraphics[scale = 0.5]{lc_texture_se_4} \\

\includegraphics[scale = 0.5]{lc_texture_se_5} & \includegraphics[scale = 0.5]{lc_texture_se_6}
\end{tabular}
\end{center}
\end{table}




<<echo=FALSE, fig.show='hide'>>=
for (i in 1:6) {
  lc_smoothness_se <- linearity_check(data_set = training_sets[[i]],
                                    variable_name = "smoothness_se")
  
  mypath <- "D:\\Users\\Documents\\sem_6_project\\project_rnw"
  
  ggsave(plot = lc_smoothness_se,
        path = mypath,
        width = 6,
        height = 6,
        device='png',
        dpi=500,
        filename = glue("lc_smoothness_se_{i}.png"),
        units = "in",
        bg = "white")
}
@
\newpage
\begin{table}[H]
\caption*{Linearity Check for \textcolor{blue}{\textbf{\textit{smoothness\_se}}}}
\begin{center}
\begin{tabular}{cc}
\includegraphics[scale = 0.5]{lc_smoothness_se_1} & \includegraphics[scale = 0.5]{lc_smoothness_se_2} \\

\includegraphics[scale = 0.5]{lc_smoothness_se_3} & \includegraphics[scale = 0.5]{lc_smoothness_se_4} \\

\includegraphics[scale = 0.5]{lc_smoothness_se_5} & \includegraphics[scale = 0.5]{lc_smoothness_se_6}
\end{tabular}
\end{center}
\end{table}




<<echo=FALSE, fig.show='hide'>>=
for (i in 1:6) {
  lc_concavity_se <- linearity_check(data_set = training_sets[[i]],
                                    variable_name = "concavity_se")
  
  mypath <- "D:\\Users\\Documents\\sem_6_project\\project_rnw"
  
  ggsave(plot = lc_concavity_se,
        path = mypath,
        width = 6,
        height = 6,
        device='png',
        dpi=500,
        filename = glue("lc_concavity_se_{i}.png"),
        units = "in",
        bg = "white")
}
@
\newpage
\begin{table}[H]
\caption*{Linearity Check for \textcolor{blue}{\textbf{\textit{concavity\_se}}}}
\begin{center}
\begin{tabular}{cc}
\includegraphics[scale = 0.5]{lc_concavity_se_1} & \includegraphics[scale = 0.5]{lc_concavity_se_2} \\

\includegraphics[scale = 0.5]{lc_concavity_se_3} & \includegraphics[scale = 0.5]{lc_concavity_se_4} \\

\includegraphics[scale = 0.5]{lc_concavity_se_5} & \includegraphics[scale = 0.5]{lc_concavity_se_6}
\end{tabular}
\end{center}
\end{table}




<<echo=FALSE, fig.show='hide'>>=
for (i in 1:6) {
  lc_symmetry_se <- linearity_check(data_set = training_sets[[i]],
                                    variable_name = "symmetry_se")
  
  mypath <- "D:\\Users\\Documents\\sem_6_project\\project_rnw"
  
  ggsave(plot = lc_symmetry_se,
        path = mypath,
        width = 6,
        height = 6,
        device='png',
        dpi=500,
        filename = glue("lc_symmetry_se_{i}.png"),
        units = "in",
        bg = "white")
}
@
\newpage
\begin{table}[H]
\caption*{Linearity Check for \textcolor{blue}{\textbf{\textit{symmetry\_se}}}}
\begin{center}
\begin{tabular}{cc}
\includegraphics[scale = 0.5]{lc_symmetry_se_1} & \includegraphics[scale = 0.5]{lc_symmetry_se_2} \\

\includegraphics[scale = 0.5]{lc_symmetry_se_3} & \includegraphics[scale = 0.5]{lc_symmetry_se_4} \\

\includegraphics[scale = 0.5]{lc_symmetry_se_5} & \includegraphics[scale = 0.5]{lc_symmetry_se_6}
\end{tabular}
\end{center}
\end{table}




<<echo=FALSE, fig.show='hide'>>=
for (i in 1:6) {
  lc_fractal_dimension_se <- linearity_check(data_set = training_sets[[i]],
                                    variable_name = "fractal_dimension_se")
  
  mypath <- "D:\\Users\\Documents\\sem_6_project\\project_rnw"
  
  ggsave(plot = lc_fractal_dimension_se,
        path = mypath,
        width = 6,
        height = 6,
        device='png',
        dpi=500,
        filename = glue("lc_fractal_dimension_se_{i}.png"),
        units = "in",
        bg = "white")
}
@
\newpage
\begin{table}[H]
\caption*{Linearity Check for \textcolor{blue}{\textbf{\textit{fractal\_dimension\_se}}}}
\begin{center}
\begin{tabular}{cc}
\includegraphics[scale = 0.5]{lc_fractal_dimension_se_1} & \includegraphics[scale = 0.5]{lc_fractal_dimension_se_2} \\

\includegraphics[scale = 0.5]{lc_fractal_dimension_se_3} & \includegraphics[scale = 0.5]{lc_fractal_dimension_se_4} \\

\includegraphics[scale = 0.5]{lc_fractal_dimension_se_5} & \includegraphics[scale = 0.5]{lc_fractal_dimension_se_6}
\end{tabular}
\end{center}
\end{table}




<<echo=FALSE, fig.show='hide'>>=
for (i in 1:6) {
  lc_radius_worst <- linearity_check(data_set = training_sets[[i]],
                                    variable_name = "radius_worst")
  
  mypath <- "D:\\Users\\Documents\\sem_6_project\\project_rnw"
  
  ggsave(plot = lc_radius_worst,
        path = mypath,
        width = 6,
        height = 6,
        device='png',
        dpi=500,
        filename = glue("lc_radius_worst_{i}.png"),
        units = "in",
        bg = "white")
}
@
\newpage

\begin{table}[H]
\caption*{Linearity Check for \textcolor{blue}{\textbf{\textit{radius\_worst}}}}
\begin{center}
\begin{tabular}{cc}
\includegraphics[scale = 0.5]{lc_radius_worst_1} & \includegraphics[scale = 0.5]{lc_radius_worst_2} \\

\includegraphics[scale = 0.5]{lc_radius_worst_3} & \includegraphics[scale = 0.5]{lc_radius_worst_4} \\

\includegraphics[scale = 0.5]{lc_radius_worst_5} & \includegraphics[scale = 0.5]{lc_radius_worst_6}
\end{tabular}
\end{center}
\end{table}




<<echo=FALSE, fig.show='hide'>>=
for (i in 1:6) {
  lc_texture_worst <- linearity_check(data_set = training_sets[[i]],
                                    variable_name = "texture_worst")
  
  mypath <- "D:\\Users\\Documents\\sem_6_project\\project_rnw"
  
  ggsave(plot = lc_texture_worst,
        path = mypath,
        width = 6,
        height = 6,
        device='png',
        dpi=500,
        filename = glue("lc_texture_worst_{i}.png"),
        units = "in",
        bg = "white")
}
@

\newpage

\begin{table}[H]
\caption*{Linearity Check for \textcolor{blue}{\textbf{\textit{texture\_worst}}}}
\begin{center}
\begin{tabular}{cc}
\includegraphics[scale = 0.5]{lc_texture_worst_1} & \includegraphics[scale = 0.5]{lc_texture_worst_2} \\

\includegraphics[scale = 0.5]{lc_texture_worst_3} & \includegraphics[scale = 0.5]{lc_texture_worst_4} \\

\includegraphics[scale = 0.5]{lc_texture_worst_5} & \includegraphics[scale = 0.5]{lc_texture_worst_6}
\end{tabular}
\end{center}
\end{table}




<<echo=FALSE, fig.show='hide'>>=
for (i in 1:6) {
  lc_smoothness_worst <- linearity_check(data_set = training_sets[[i]],
                                    variable_name = "smoothness_worst")
  
  mypath <- "D:\\Users\\Documents\\sem_6_project\\project_rnw"
  
  ggsave(plot = lc_smoothness_worst,
        path = mypath,
        width = 6,
        height = 6,
        device='png',
        dpi=500,
        filename = glue("lc_smoothness_worst_{i}.png"),
        units = "in",
        bg = "white")
}
@
\newpage

\begin{table}[H]
\caption*{Linearity Check for \textcolor{blue}{\textbf{\textit{smoothness\_worst}}}}
\begin{center}
\begin{tabular}{cc}
\includegraphics[scale = 0.5]{lc_smoothness_worst_1} & \includegraphics[scale = 0.5]{lc_smoothness_worst_2} \\

\includegraphics[scale = 0.5]{lc_smoothness_worst_3} & \includegraphics[scale = 0.5]{lc_smoothness_worst_4} \\

\includegraphics[scale = 0.5]{lc_smoothness_worst_5} & \includegraphics[scale = 0.5]{lc_smoothness_worst_6}
\end{tabular}
\end{center}
\end{table}




<<echo=FALSE, fig.show='hide'>>=
for (i in 1:6) {
  lc_concavity_worst <- linearity_check(data_set = training_sets[[i]],
                                    variable_name = "concavity_worst")
  
  mypath <- "D:\\Users\\Documents\\sem_6_project\\project_rnw"
  
  ggsave(plot = lc_concavity_worst,
        path = mypath,
        width = 6,
        height = 6,
        device='png',
        dpi=500,
        filename = glue("lc_concavity_worst_{i}.png"),
        units = "in",
        bg = "white")
}
@
\newpage

\begin{table}[H]
\caption*{Linearity Check for \textcolor{blue}{\textbf{\textit{concavity\_worst}}}}
\begin{center}
\begin{tabular}{cc}
\includegraphics[scale = 0.5]{lc_concavity_worst_1} & \includegraphics[scale = 0.5]{lc_concavity_worst_2} \\

\includegraphics[scale = 0.5]{lc_concavity_worst_3} & \includegraphics[scale = 0.5]{lc_concavity_worst_4} \\

\includegraphics[scale = 0.5]{lc_concavity_worst_5} & \includegraphics[scale = 0.5]{lc_concavity_worst_6}
\end{tabular}
\end{center}
\end{table}




<<echo=FALSE, fig.show='hide'>>=
for (i in 1:6) {
  lc_symmetry_worst <- linearity_check(data_set = training_sets[[i]],
                                    variable_name = "symmetry_worst")
  
  mypath <- "D:\\Users\\Documents\\sem_6_project\\project_rnw"
  
  ggsave(plot = lc_symmetry_worst,
        path = mypath,
        width = 6,
        height = 6,
        device='png',
        dpi=500,
        filename = glue("lc_symmetry_worst_{i}.png"),
        units = "in",
        bg = "white")
}
@

\newpage

\begin{table}[H]
\caption*{Linearity Check for \textcolor{blue}{\textbf{\textit{symmetry\_worst}}}}
\begin{center}
\begin{tabular}{cc}
\includegraphics[scale = 0.5]{lc_symmetry_worst_1} & \includegraphics[scale = 0.5]{lc_symmetry_worst_2} \\

\includegraphics[scale = 0.5]{lc_symmetry_worst_3} & \includegraphics[scale = 0.5]{lc_symmetry_worst_4} \\

\includegraphics[scale = 0.5]{lc_symmetry_worst_5} & \includegraphics[scale = 0.5]{lc_symmetry_worst_6}
\end{tabular}
\end{center}
\end{table}




<<echo=FALSE, fig.show='hide'>>=
for (i in 1:6) {
  lc_fractal_dimension_worst <- linearity_check(data_set = training_sets[[i]],
                                    variable_name = "fractal_dimension_worst")
  
  mypath <- "D:\\Users\\Documents\\sem_6_project\\project_rnw"
  
  ggsave(plot = lc_fractal_dimension_worst,
        path = mypath,
        width = 6,
        height = 6,
        device='png',
        dpi=500,
        filename = glue("lc_fractal_dimension_worst_{i}.png"),
        units = "in",
        bg = "white")
}
@

\newpage

\begin{table}[H]
\caption*{Linearity Check for \textcolor{blue}{\textbf{\textit{fractal\_dimension\_worst}}}}
\begin{center}
\begin{tabular}{cc}
\includegraphics[scale = 0.5]{lc_fractal_dimension_worst_1} & \includegraphics[scale = 0.5]{lc_fractal_dimension_worst_2} \\

\includegraphics[scale = 0.5]{lc_fractal_dimension_worst_3} & \includegraphics[scale = 0.5]{lc_fractal_dimension_worst_4} \\

\includegraphics[scale = 0.5]{lc_fractal_dimension_worst_5} & \includegraphics[scale = 0.5]{lc_fractal_dimension_worst_6}
\end{tabular}
\end{center}
\end{table}




\newpage

\subsubsection{\textcolor{red}{Data Reduction - Phase 2}}

$\bullet$ \textbf{\textit{\textcolor{blue}{fractal\_dimension\_mean}}}, \textbf{\textit{\textcolor{blue}{texture\_se}}}, \textbf{\textit{\textcolor{blue}{smoothness\_se}}}, \textbf{\textit{\textcolor{blue}{concavity\_se}}},  \textbf{\textit{\textcolor{blue}{symmetry\_se}}}, \textbf{\textit{\textcolor{blue}{fractal\_dimension\_se}}} are dropped as they are violating the linearity assumption. \\

<<echo=FALSE>>=
train <- subset(train, select = -c(fractal_dimension_mean,
                                   texture_se,
                                   smoothness_se,
                                   concavity_se,
                                   fractal_dimension_se,
                                   symmetry_se))
@

We also adjust the \textbf{\textit{Test Set}} accordingly.

<<echo=FALSE>>=
test <- subset(test, select = -c(fractal_dimension_mean,
                                 texture_se,
                                 smoothness_se,
                                 concavity_se,
                                 fractal_dimension_se,
                                 symmetry_se))
@

% We also adjust the newly created training sets and test sets accordingly.

<<echo=FALSE>>=
training_sets[[1]] <- train; test_sets[[1]] <- test

for (i in 2:6) {
  training_sets[[i]] <- subset(training_sets[[i]], 
                               select = -c(id,
                                   diagnosis,
                                   perimeter_mean,
                                   area_mean,
                                   perimeter_se,
                                   area_se,
                                   compactness_mean,
                                   compactness_se,
                                   concave.points_mean,
                                   concave.points_se,
                                   perimeter_worst,
                                   area_worst,
                                   compactness_worst,
                                   concave.points_worst,
                                   fractal_dimension_mean,
                                   texture_se,
                                   smoothness_se,
                                   concavity_se,
                                   fractal_dimension_se,
                                   symmetry_se))
  
  
  
  test_sets[[i]] <- subset(test_sets[[i]], 
                               select = -c(id,
                                   diagnosis,
                                   perimeter_mean,
                                   area_mean,
                                   perimeter_se,
                                   area_se,
                                   compactness_mean,
                                   compactness_se,
                                   concave.points_mean,
                                   concave.points_se,
                                   perimeter_worst,
                                   area_worst,
                                   compactness_worst,
                                   concave.points_worst,
                                   fractal_dimension_mean,
                                   texture_se,
                                   smoothness_se,
                                   concavity_se,
                                   fractal_dimension_se,
                                   symmetry_se))
}
@


\vspace{1cm}

\section{\textcolor{COL1}{Model Fitting}}

\hspace{1cm} We observe that the \textit{\textbf{mean}} variables and the \textit{\textbf{worst}} variables are highly correlated. The \textit{\textbf{worst}} variables capture less information as compared to \textit{\textbf{mean}} variables; but many of the \textit{\textbf{worst}} variables have strong linear relation with the log odds of the response variable. So it will be unwise to drop any one group of variables. Rather we split the \textit{\textbf{Training Set}} into two parts; one having the \textit{\textbf{mean}} and \textit{\textbf{se}} variables, the other one having the \textit{\textbf{se}} and \textit{\textbf{worst}} variables. We fit models on both types of training sets and finally we shall stick with the model having better accuracy.

<<>>=
train_ms <- train[,1:7]
train_sw <- train[c(1, 7:13)]

test_ms <- test[,1:7]
test_sw <- test[c(1, 7:13)]
@

% We also split other training and test sets.

<<echo=FALSE>>=
training_sets_ms <- training_sets
test_sets_ms <- test_sets

training_sets_sw <- training_sets
test_sets_sw <- test_sets

for (i in 1:6) {
  training_sets_ms[[i]] <- training_sets[[i]][,1:7]
  training_sets_sw[[i]] <- training_sets[[i]][c(1, 7:13)]
  
  test_sets_ms[[i]] <- test_sets[[i]][,1:7]
  test_sets_sw[[i]] <- test_sets[[i]][c(1, 7:13)]
}
@


\subsection{\textcolor{col2}{Model with \textit{\textbf{mean}} and \textit{\textbf{se}} variables}}

\subsubsection{\textcolor{col5}{The Logistic Regression Equation}}

Here our regression equation is :

$$ P(Y = 1 | X_1, X_2, \ldots , X_6) = \dfrac{1}{1+e^{-(\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \ldots + \beta_6 X_6 )}} $$

where $ P(Y = 1 | X_1, X_2, \ldots , X_6) $ is the probability of \textbf{\textit{\textcolor{col7}{Malignancy}}};\\

$\beta_0$ is the intercept term; \\

$X_1$ is \textbf{\textit{\textcolor{blue}{radius\_mean}}}; \\

$X_2$ is \textbf{\textit{\textcolor{blue}{texture\_mean}}}; \\

$X_3$ is \textbf{\textit{\textcolor{blue}{smoothness\_mean}}}; \\

$X_4$ is \textbf{\textit{\textcolor{blue}{concavity\_mean}}}; \\

$X_5$ is \textbf{\textit{\textcolor{blue}{symmetry\_mean}}}; \\

$X_6$ is \textbf{\textit{\textcolor{blue}{radius\_se}}}; \\

$\beta_1$, $\beta_2$, $\ldots$ , $\beta_6$ are the coefficients associated with the predictors respectively; indicating how much the log-odds of the outcome change with one-unit increase in each predictor. \\

\newpage

$\spadesuit$ The model can be represented as :

$$ \log \left( \dfrac{p}{1-p} \right) =  \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \ldots + \beta_6 X_6 . $$

where $p$ is the probability of \textbf{\textit{\textcolor{col7}{Malignancy}}}. \\

\hspace{1cm} $\left( \dfrac{p}{1-p} \right)$ is called the \textbf{\textit{Odds of \textcolor{col7}{Malignancy}}} and consequently $\log \left( \dfrac{p}{1-p} \right)$ is called \textbf{\textit{Log-odds of \textcolor{col7}{Malignancy}}} or \textbf{\textit{logit $p$}}. \\

\subsubsection{\textcolor{col5}{Visualizations Regarding the Predictors}}

$\clubsuit$ {\textcolor{col14}{\textbf{Correlation Matrix}}} \\

Let us have a look at the correlation matrix of the predictors.

<<echo=FALSE, fig.show='hide'>>=
cor_train_ms <- cor(train_ms[,2:7])

ggcorrplot(cor_train_ms,
           method = "square",
           type = "lower",
           lab = TRUE,
           lab_col = "black",
           lab_size = 5,
           outline.color = "white",
           tl.cex = 20,
           legend.title = "") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        panel.background = element_rect(fill = "white"),
        panel.grid.major = element_blank(),
        panel.border = element_blank(),
        legend.key.height = unit(3, 'cm'),
        legend.key.width = unit(1, 'cm'))
@

<<echo=FALSE>>=
ggsave(path = "D:\\Users\\Documents\\sem_6_project\\project_rnw",
       width = 10,
       height = 10,
       device='png',
       dpi=1000,
       filename = "cor_mat_train_ms.png",
       units = "in",
       bg = "white")
@


\begin{figure}[!htbp]
\centering
\includegraphics[scale = 0.5]{cor_mat_train_ms}
\end{figure}

To visualize all the variables in a single plot, we scale them in the range $(0, 1)$.

\newpage

$\clubsuit$ {\textcolor{col14}{\textbf{Box Plot}}} \\


<<echo=FALSE>>=
scaler_func <- function(x) { (x - min(x)) / (max(x) - min(x)) }
@

<<echo=FALSE>>=
train_ms_scaled <- apply(train_ms[,2:7], 2, scaler_func )

temp1 <- ifelse(train_ms$diagnosis_encoded == 0, "Benign", "Malignant")

train_ms_scaled <- data.frame(diagnosis = temp1,
                              train_ms_scaled)
@

% We reformat the data for our convenience.

<<echo=FALSE, fig.show='hide'>>=
train_ms_ref <- gather(train_ms_scaled,
                       key = "variable",
                       value = "value",
                       -c("diagnosis"))

train_ms_ref %>%
  ggplot(aes(x = variable, y = value, fill = diagnosis)) +
  stat_boxplot(geom = "errorbar", linewidth = 0.7) +
  geom_boxplot(outlier.shape = 18) +
  labs(x = "", y = "") +
  theme(legend.position = "top")
@

<<echo=FALSE>>=
ggsave(path = "D:\\Users\\Documents\\sem_6_project\\project_rnw",
       width = 13,
       height = 10,
       device = 'png',
       dpi = 1000,
       filename = "model_1_box_plot.png",
       units = "in",
       bg = "white")
@


\begin{figure}[!htbp]
\centering
\includegraphics[scale = 0.42]{model_1_box_plot}
\end{figure}

$\clubsuit$ {\textcolor{col14}{\textbf{Swarm Plot}}} \\

<<echo=FALSE, fig.show='hide'>>=
train_ms_ref %>%
  ggplot(aes(x = variable, y = value, group = diagnosis, colour = diagnosis)) +
  geom_beeswarm() +
  theme(legend.position = "top")
@

<<echo=FALSE>>=
ggsave(path = "D:\\Users\\Documents\\sem_6_project\\project_rnw",
       width = 13,
       height = 10,
       device = 'png',
       dpi = 1000,
       filename = "model_1_swarm_plot.png",
       units = "in",
       bg = "white")
@


\begin{figure}[!htbp]
\centering
\includegraphics[scale = 0.42]{model_1_swarm_plot}
\end{figure}

\newpage

\subsubsection{\textcolor{col5}{Fitting by \textbf{glm()}}}

<<>>=
fit_ms_1 <- glm(diagnosis_encoded ~ ., data = train_ms, family = binomial)
summary(fit_ms_1)
@


\subsubsection{\textcolor{col5}{Checking Variance Inflation Factor}}

\ding{247} \hspace{0.5cm} Variance Inflation Factor (VIF) is a measure used in statistical regression analysis to assess the severity of multicollinearity in a set of variables. \\

\hspace{1cm} VIF quantifies how much the variance of a regression coefficient is inflated due to multicollinearity. \\

$\bullet$ VIF for $j$-th predictor is given by $$ VIF_j = \dfrac{1}{1-R_j^2} $$ where $R_j^2$ is the $R^2$ value obtained from a regression of the $j$-th predictor against all other predictors.

<<>>=
vif(fit_ms_1)
@

\smallpencil \hspace{0.5cm} All the VIFs are pretty small, the maximum being \Sexpr{max(vif(fit_ms_1))}; so we are ensured that multicollinearity is not a significant concern among the predictor variables in our regression model.

\newpage

\subsection{\textcolor{col2}{Model with \textit{\textbf{se}} and \textit{\textbf{worst}} variables}}

\subsubsection{\textcolor{col5}{The Logistic Regression Equation}}

Here our regression equation is :

$$ P(Y = 1 | X_1, X_2, \ldots , X_7) = \dfrac{1}{1+e^{-(\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \ldots + \beta_7 X_7 )}} $$

where $ P(Y = 1 | X_1, X_2, \ldots , X_7) $ is the probability of \textbf{\textit{\textcolor{col7}{Malignancy}}};\\

$\beta_0$ is the intercept term; \\

$X_1$ is \textbf{\textit{\textcolor{blue}{radius\_se}}}; \\

$X_2$ is \textbf{\textit{\textcolor{blue}{radius\_worst}}}; \\

$X_3$ is \textbf{\textit{\textcolor{blue}{texture\_worst}}}; \\

$X_4$ is \textbf{\textit{\textcolor{blue}{smoothness\_worst}}}; \\

$X_5$ is \textbf{\textit{\textcolor{blue}{concavity\_worst}}}; \\

$X_6$ is \textbf{\textit{\textcolor{blue}{symmetry\_worst}}}; \\

$X_7$ is \textbf{\textit{\textcolor{blue}{fractal\_dimension\_worst}}}; \\

$\beta_1$, $\beta_2$, $\ldots$ , $\beta_7$ are the coefficients associated with the predictors respectively. \\

$\spadesuit$ The model can be represented as :

$$ \log \left( \dfrac{p}{1-p} \right) =  \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \ldots + \beta_7 X_7 . $$

where $p$ is the probability of \textbf{\textit{\textcolor{col7}{Malignancy}}}. \\

\newpage

\subsubsection{\textcolor{col5}{Visualizations Regarding the Predictors}}

$\clubsuit$ {\textcolor{col14}{\textbf{Correlation Matrix}}} \\

We take a glance of the correlation matrix of the predictors.

<<echo=FALSE, fig.show='hide'>>=
cor_train_sw <- cor(train_sw[,2:8])

ggcorrplot(cor_train_sw,
           method = "square",
           type = "lower",
           lab = TRUE,
           lab_col = "black",
           lab_size = 5,
           outline.color = "white",
           tl.cex = 20,
           legend.title = "") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        panel.background = element_rect(fill = "white"),
        panel.grid.major = element_blank(),
        panel.border = element_blank(),
        legend.key.height = unit(3, 'cm'),
        legend.key.width = unit(1, 'cm'))
@

<<echo=FALSE>>=
ggsave(path = "D:\\Users\\Documents\\sem_6_project\\project_rnw",
       width = 10,
       height = 10,
       device='png',
       dpi=1000,
       filename = "cor_mat_train_sw.png",
       units = "in",
       bg = "white")
@

\begin{figure}[!htbp]
\centering
\includegraphics[scale = 0.5]{cor_mat_train_sw}
\end{figure}

To visualize all the variables in a single plot, we scale them in the range $(0, 1)$.

\newpage

$\clubsuit$ {\textcolor{col14}{\textbf{Box Plot}}} \\


<<echo=FALSE>>=
train_sw_scaled <- apply(train_sw[,2:8], 2, scaler_func )

temp2 <- ifelse(train_sw$diagnosis_encoded == 0, "Benign", "Malignant")

train_sw_scaled <- data.frame(diagnosis = temp2,
                              train_sw_scaled)
@

% We reformat the data for our convenience.

<<echo=FALSE, fig.show='hide'>>=
train_sw_ref <- gather(train_sw_scaled,
                       key = "variable",
                       value = "value",
                       -c("diagnosis"))

train_sw_ref %>%
  ggplot(aes(x = variable, y = value, fill = diagnosis)) +
  stat_boxplot(geom = "errorbar", linewidth = 0.7) +
  geom_boxplot(outlier.shape = 18) +
  labs(x = "", y = "") +
  theme(legend.position = "top")
@

<<echo=FALSE>>=
ggsave(path = "D:\\Users\\Documents\\sem_6_project\\project_rnw",
       width = 14,
       height = 10,
       device='png',
       dpi=1000,
       filename = "model_2_box_plot.png",
       units = "in",
       bg = "white")
@


\begin{figure}[!htbp]
\centering
\includegraphics[scale = 0.42]{model_2_box_plot}
\end{figure}

$\clubsuit$ {\textcolor{col14}{\textbf{Swarm Plot}}} \\

<<echo=FALSE, fig.show='hide'>>=
train_sw_ref %>%
  ggplot(aes(x = variable, y = value, group = diagnosis, colour = diagnosis)) +
  geom_beeswarm() +
  theme(legend.position = "top")
@

<<echo=FALSE>>=
ggsave(path = "D:\\Users\\Documents\\sem_6_project\\project_rnw",
       width = 13,
       height = 10,
       device = 'png',
       dpi = 1000,
       filename = "model_2_swarm_plot.png",
       units = "in",
       bg = "white")
@


\begin{figure}[!htbp]
\centering
\includegraphics[scale = 0.42]{model_2_swarm_plot}
\end{figure}

\newpage

\subsubsection{\textcolor{col5}{Fitting by \textbf{glm()}}}

<<>>=
fit_sw_1 <- glm(diagnosis_encoded ~ ., data = train_sw, family = binomial)
summary(fit_sw_1)
@

\subsubsection{\textcolor{col5}{Checking Variance Inflation Factor}}

<<>>=
vif(fit_sw_1)
@

\smallpencil \hspace{0.5cm} All the VIFs are within tolerance limit, the maximum being \Sexpr{max(vif(fit_sw_1))}; so for this model also we are ensured that multicollinearity is not a significant concern among the predictor variables in our regression equation.

\newpage

\section{\textcolor{COL1}{Assessing the Fit}}

\subsection{\textcolor{col2}{Model with \textit{\textbf{mean}} and \textit{\textbf{se}} variables}}

\subsubsection{\textcolor{col5}{Jitter Plot of Outcome vs Predicted Probability}}

The following is a scatterplot with \textbf{\textit{predicted probabilities}} on the $x$-axis and the \textbf{\textit{outcome}} on the $y$-axis. The points are jittered randomly so as to stop overlapping and make it easier to visualize.

<<echo=FALSE, fig.show='hide'>>=
d1 <- ifelse(train_ms$diagnosis_encoded == 0, "Benign", "Malignant")

df1 <- data.frame(pred_probs = predict(fit_ms_1, type = "response"),
                  diagnosis = as.factor(d1))

df1 %>%
  ggplot(aes(x = pred_probs, y = diagnosis, colour = diagnosis)) +
  geom_jitter(position = position_jitter(0.2), size = 1.5) +
  theme(legend.position = "top",
        axis.text.y = element_text(angle = 90, hjust = 0.5)) +
  labs(x = "Predicted Probability", y = "Jittered Diagnosis Outcome")
@

<<echo=FALSE>>=
ggsave(path = "D:\\Users\\Documents\\sem_6_project\\project_rnw",
       width = 10,
       height = 10,
       device = 'png',
       dpi = 1000,
       filename = "model_1_jitter_plot.png",
       units = "in",
       bg = "white")
@

\begin{figure}[H]
\centering
\includegraphics[scale = 0.6]{model_1_jitter_plot}
\end{figure}

$\blacktriangleright$ Most of the cases with lower probabilities are correctly identified as \textbf{\textit{\textcolor{col8}{Benign}}}. Likewise most of the cases with higher probabilities are correctly identified as \textbf{\textit{\textcolor{col7}{Malignant}}}. But there are also few cases where the model predicts low probability but the diagnosis is \textbf{\textit{\textcolor{col7}{Malignant}}}.

\subsubsection{\textcolor{col5}{Log Odds vs Predictors}}

A scatterplot of estimated log-odds and a predictor is insightful to check the linearity assumption of the model.

<<echo=FALSE>>=
logodds_1 <- fit_ms_1$linear.predictors

linearity_check_df_1 <- cbind(train_ms, logodds_1)
@

<<echo=FALSE, warning=FALSE, message=FALSE, fig.show='hide', tidy=FALSE>>=
linearity_check_df_1 %>%
  ggplot(aes(x = radius_mean, y = logodds_1)) +
  geom_point(size = 1, col = "red") +
  geom_smooth(method = "lm", formula = y ~ x) +
  labs(x = "Radius Mean", y = "Log Odds", title = "Log-odds ~ radius_mean")
@

<<echo=FALSE>>=
ggsave(path = "D:\\Users\\Documents\\sem_6_project\\project_rnw",
       width = 6,
       height = 6,
       device = 'png',
       dpi = 1000,
       filename = "model_1_logodds_radius_mean.png",
       units = "in",
       bg = "white")
@

<<echo=FALSE, warning=FALSE, message=FALSE, fig.show='hide', tidy=FALSE>>=
linearity_check_df_1 %>%
  ggplot(aes(x = texture_mean, y = logodds_1)) +
  geom_point(size = 1, col = "red") +
  geom_smooth(method = "lm", formula = y ~ x) +
  labs(x = "Texture Mean", y = "Log Odds", title = "Log-odds ~ texture_mean")
@

<<echo=FALSE>>=
ggsave(path = "D:\\Users\\Documents\\sem_6_project\\project_rnw",
       width = 6,
       height = 6,
       device = 'png',
       dpi = 1000,
       filename = "model_1_logodds_texture_mean.png",
       units = "in",
       bg = "white")
@

<<echo=FALSE, warning=FALSE, message=FALSE, fig.show='hide', tidy=FALSE>>=
linearity_check_df_1 %>%
  ggplot(aes(x = smoothness_mean, y = logodds_1)) +
  geom_point(size = 1, col = "red") +
  geom_smooth(method = "lm", formula = y ~ x) +
  labs(x = "Smoothness Mean", y = "Log Odds", title = "Log-odds ~ smoothness_mean")
@

<<echo=FALSE>>=
ggsave(path = "D:\\Users\\Documents\\sem_6_project\\project_rnw",
       width = 6,
       height = 6,
       device = 'png',
       dpi = 1000,
       filename = "model_1_logodds_smoothness_mean.png",
       units = "in",
       bg = "white")
@

<<echo=FALSE, warning=FALSE, message=FALSE, fig.show='hide', tidy=FALSE>>=
linearity_check_df_1 %>%
  ggplot(aes(x = concavity_mean, y = logodds_1)) +
  geom_point(size = 1, col = "red") +
  geom_smooth(method = "lm", formula = y ~ x) +
  labs(x = "Concavity Mean", y = "Log Odds", title = "Log-odds ~ concavity_mean")
@

<<echo=FALSE>>=
ggsave(path = "D:\\Users\\Documents\\sem_6_project\\project_rnw",
       width = 6,
       height = 6,
       device = 'png',
       dpi = 1000,
       filename = "model_1_logodds_concavity_mean.png",
       units = "in",
       bg = "white")
@

<<echo=FALSE, warning=FALSE, message=FALSE, fig.show='hide', tidy=FALSE>>=
linearity_check_df_1 %>%
  ggplot(aes(x = symmetry_mean, y = logodds_1)) +
  geom_point(size = 1, col = "red") +
  geom_smooth(method = "lm", formula = y ~ x) +
  labs(x = "Symmetry Mean", y = "Log Odds", title = "Log-odds ~ symmetry_mean")
@

<<echo=FALSE>>=
ggsave(path = "D:\\Users\\Documents\\sem_6_project\\project_rnw",
       width = 6,
       height = 6,
       device = 'png',
       dpi = 1000,
       filename = "model_1_logodds_symmetry_mean.png",
       units = "in",
       bg = "white")
@

<<echo=FALSE, warning=FALSE, message=FALSE, fig.show='hide', tidy=FALSE>>=
linearity_check_df_1 %>%
  ggplot(aes(x = radius_se, y = logodds_1)) +
  geom_point(size = 1, col = "red") +
  geom_smooth(method = "lm", formula = y ~ x) +
  labs(x = "Radius SE", y = "Log Odds", title = "Log-odds ~ radius_se")
@

<<echo=FALSE>>=
ggsave(path = "D:\\Users\\Documents\\sem_6_project\\project_rnw",
       width = 6,
       height = 6,
       device = 'png',
       dpi = 1000,
       filename = "model_1_logodds_radius_se.png",
       units = "in",
       bg = "white")
@

\newpage

\begin{table}[H]
\caption*{Log-odds vs Predictors of the Model}
\begin{center}
\begin{tabular}{cc}
\includegraphics[scale = 0.5]{model_1_logodds_radius_mean} & \includegraphics[scale = 0.5]{model_1_logodds_texture_mean} \\

\includegraphics[scale = 0.5]{model_1_logodds_smoothness_mean} & \includegraphics[scale = 0.5]{model_1_logodds_concavity_mean} \\

\includegraphics[scale = 0.5]{model_1_logodds_symmetry_mean} & \includegraphics[scale = 0.5]{model_1_logodds_radius_se}
\end{tabular}
\end{center}
\end{table}

\newpage

\subsubsection{\textcolor{col5}{Confusion Matrix and Evaluation Metrics}}

Now we shall run our model on the \textbf{\textit{Test Set}} and evaluate different evaluation metrics.

<<>>=
probs_1 <- predict(fit_ms_1, newdata = test_ms, type = "response")
@

$\bullet$ We use 0.5 as our threshold value. \\

<<echo=FALSE>>=
preds_1 <- ifelse(probs_1 >= 0.5, "Malignant", "Benign")
outcome_1 <- ifelse(test_ms$diagnosis_encoded == 1, "Malignant", "Benign")
cm_1 <- table(outcome_1, preds_1)
@

<<echo=FALSE>>=
cm_df_1 <- as.data.frame(cm_1)
cm_df_1$type <- c("True Positive", "False Positive", "False Negative", "True Negative")
@

<<tidy=FALSE, highlight=TRUE, echo=FALSE, fig.show='hide'>>=
cm_df_1 %>%
ggplot(aes(y = preds_1, x = outcome_1, fill = Freq)) +
  geom_tile(color = "white") +
  geom_text(aes(label = glue("{type} - {Freq}"))) +
  scale_fill_gradient(low = "#F01181", high = "#49FE00") +
  labs(title = "Confusion Matrix for Model 1",
       x = "Predicted",
       y = "Actual") +
  theme_minimal() +
  scale_x_discrete(labels = c("Benign", "Malignant")) +
  scale_y_discrete(labels = c("Benign", "Malignant")) +
  theme(axis.text.y = element_text(angle = 90, hjust = 0.5),
        legend.position = "none")
@

<<echo=FALSE>>=
ggsave(path = "D:\\Users\\Documents\\sem_6_project\\project_rnw",
       width = 10,
       height = 10,
       device = 'png',
       dpi = 1000,
       filename = "model_1_confusion_matrix.png",
       units = "in",
       bg = "white")
@

\begin{figure}[H]
\centering
\includegraphics[scale = 0.6]{model_1_confusion_matrix}
\end{figure}


\newpage

Different evaluation metrics are given as follows : \\


$\blacktriangleright$ \textcolor{col13}{\textbf{\textit{Accuracy}}} indicates how many labels out of the total labels are predicted correctly by a classification model. $$\text{Accuracy} = \dfrac{\text{TP} + \text{TN}}{\text{TP} + \text{TN} + \text{FP} + \text{FN}}$$

\vspace{0.5cm}

where \textbf{True Positive (TP)} is the actual class of the observations that are  \textbf{\textit{\textcolor{col8}{Benign}}} and the model also predicts it as \textbf{\textit{\textcolor{col8}{Benign}}}. \\

\textbf{True Negative (TN)} is the actual class of the observations that are \textbf{\textit{\textcolor{col7}{Malignant}}} and the model also predicts it as \textbf{\textit{\textcolor{col7}{Malignant}}}. \\

\textbf{False Positive (FP)} is the actual class of the observations that are \textbf{\textit{\textcolor{col7}{Malignant}}} but the model predicts it incorrectly as \textbf{\textit{\textcolor{col8}{Benign}}}. \\

\textbf{False Negative (FN)} is the actual class of the observations that are \textbf{\textit{\textcolor{col8}{Benign}}} but the model predicts it incorrectly as \textbf{\textit{\textcolor{col7}{Malignant}}}. \\


For model 1, \textcolor{col13}{\textbf{\textit{accuracy}}} is \Sexpr{(cm_1[1] + cm_1[4])/(sum(cm_1))}. \\


\vspace{1cm}

$\blacktriangleright$ \textcolor{col13}{\textbf{\textit{Recall}}} is also known as sensitivity and can be defined as the ratio of the total number of correctly predicted positive examples to the total number of positive examples. A high value of recall indicates that the class is correctly recognized (a small number of FNs).

$$\text{Recall} = \dfrac{\text{TP}}{\text{TP} + \text{FN}}$$

<<echo=FALSE>>=
recall_1 <- cm_1[1] / (cm_1[1] + cm_1[3])
@
\vspace{0.5cm}

For model 1, \textcolor{col13}{\textbf{\textit{recall}}} is \Sexpr{(cm_1[1])/(cm_1[1] + cm_1[3])}. \\

\vspace{1cm}

$\blacktriangleright$ \textcolor{col13}{\textbf{\textit{Precision}}} is also known as the exactness of classifiers.

$$\text{Precision} = \dfrac{\text{TP}}{\text{TP} + \text{FP}}$$

<<echo=FALSE>>=
precision_1 <- cm_1[1] / (cm_1[1] + cm_1[2])
@
\vspace{0.5cm}

For model 1, \textcolor{col13}{\textbf{\textit{precision}}} is \Sexpr{(cm_1[1])/(cm_1[1] + cm_1[2])}. \\

\vspace{1cm}

$\blacktriangleright$ \textcolor{col13}{\textbf{\textit{F1 Score}}} is also known as the F measure and it is the harmonic mean of the precision and recall scores.

$$\text{F1 Score} = 2 \times \dfrac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$$.

For model 1, \textcolor{col13}{\textbf{\textit{F1 Score}}} is \Sexpr{(2 * recall_1 * precision_1)/(recall_1 + precision_1)}.



\newpage


\subsection{\textcolor{col2}{Model with \textit{\textbf{se}} and \textit{\textbf{worst}} variables}}

\subsubsection{\textcolor{col5}{Jitter Plot of Outcome vs Predicted Probability}}

<<tidy=FALSE, highlight=TRUE, echo=FALSE, fig.show='hide'>>=
d2 <- ifelse(train_sw$diagnosis_encoded == 0, "Benign", "Malignant")

df2 <- data.frame(pred_probs = predict(fit_sw_1, type = "response"),
                  diagnosis = as.factor(d2))

df2 %>%
  ggplot(aes(x = pred_probs, y = diagnosis, colour = diagnosis)) +
  geom_jitter(position = position_jitter(0.2), size = 1.5) +
  theme(legend.position = "top",
        axis.text.y = element_text(angle = 90, hjust = 0.5)) +
  labs(x = "Predicted Probability", y = "Jittered Diagnosis Outcome")
@

<<echo=FALSE>>=
ggsave(path = "D:\\Users\\Documents\\sem_6_project\\project_rnw",
       width = 10,
       height = 10,
       device = 'png',
       dpi = 1000,
       filename = "model_2_jitter_plot.png",
       units = "in",
       bg = "white")
@

\begin{figure}[h]
\centering
\includegraphics[scale = 0.7]{model_2_jitter_plot}
\end{figure}

$\blacktriangleright$ Most of the cases with lower probabilities are correctly identified as \textbf{\textit{\textcolor{col8}{Benign}}}. Likewise most of the cases with higher probabilities are correctly identified as \textbf{\textit{\textcolor{col7}{Malignant}}}. But there are very little number of cases where the model predicts low probability but the diagnosis is \textbf{\textit{\textcolor{col7}{Malignant}}}.

\subsubsection{\textcolor{col5}{Log Odds vs Predictors}}

Linearity assumption is more solidified from the relationship shown by scatterplot of estimated log-odds and a predictor.

\newpage

<<echo=FALSE>>=
logodds_2 <- fit_sw_1$linear.predictors

linearity_check_df_2 <- cbind(train_sw, logodds_2)
@

<<fig.show='hide', highlight=TRUE, warning=FALSE, message=FALSE, echo=FALSE>>=
linearity_check_df_2 %>%
  ggplot(aes(x = radius_se, y = logodds_2)) +
  geom_point(size = 1, col = "red") +
  geom_smooth(method = "lm", formula = y ~ x) +
  labs(x = "Radius SE", y = "Log Odds", title = "Log-odds ~ radius_se")
@

<<echo=FALSE>>=
ggsave(path = "D:\\Users\\Documents\\sem_6_project\\project_rnw",
       width = 6,
       height = 6,
       device = 'png',
       dpi = 1000,
       filename = "model_2_logodds_radius_se.png",
       units = "in",
       bg = "white")
@

<<fig.show='hide', highlight=TRUE, warning=FALSE, message=FALSE, echo=FALSE>>=
linearity_check_df_2 %>%
  ggplot(aes(x = radius_worst, y = logodds_2)) +
  geom_point(size = 1, col = "red") +
  geom_smooth(method = "lm", formula = y ~ x) +
  labs(x = "Radius Worst", y = "Log Odds", title = "Log-odds ~ radius_worst")
@

<<echo=FALSE>>=
ggsave(path = "D:\\Users\\Documents\\sem_6_project\\project_rnw",
       width = 6,
       height = 6,
       device = 'png',
       dpi = 1000,
       filename = "model_2_logodds_radius_worst.png",
       units = "in",
       bg = "white")
@

<<fig.show='hide', highlight=TRUE, warning=FALSE, message=FALSE, echo=FALSE>>=
linearity_check_df_2 %>%
  ggplot(aes(x = texture_worst, y = logodds_2)) +
  geom_point(size = 1, col = "red") +
  geom_smooth(method = "lm", formula = y ~ x) +
  labs(x = "Texture Worst", y = "Log Odds", title = "Log-odds ~ texture_worst")
@

<<echo=FALSE>>=
ggsave(path = "D:\\Users\\Documents\\sem_6_project\\project_rnw",
       width = 6,
       height = 6,
       device = 'png',
       dpi = 1000,
       filename = "model_2_logodds_texture_worst.png",
       units = "in",
       bg = "white")
@

<<fig.show='hide', highlight=TRUE, warning=FALSE, message=FALSE, echo=FALSE>>=
linearity_check_df_2 %>%
  ggplot(aes(x = smoothness_worst, y = logodds_2)) +
  geom_point(size = 1, col = "red") +
  geom_smooth(method = "lm", formula = y ~ x) +
  labs(x = "Smoothness Worst", y = "Log Odds", title = "Log-odds ~ smoothness_worst")
@

<<echo=FALSE>>=
ggsave(path = "D:\\Users\\Documents\\sem_6_project\\project_rnw",
       width = 6,
       height = 6,
       device = 'png',
       dpi = 1000,
       filename = "model_2_logodds_smoothness_worst.png",
       units = "in",
       bg = "white")
@

<<fig.show='hide', highlight=TRUE, warning=FALSE, message=FALSE, echo=FALSE>>=
linearity_check_df_2 %>%
  ggplot(aes(x = concavity_worst, y = logodds_2)) +
  geom_point(size = 1, col = "red") +
  geom_smooth(method = "lm", formula = y ~ x) +
  labs(x = "Concavity Worst", y = "Log Odds", title = "Log-odds ~ concavity_worst")
@

<<echo=FALSE>>=
ggsave(path = "D:\\Users\\Documents\\sem_6_project\\project_rnw",
       width = 6,
       height = 6,
       device = 'png',
       dpi = 1000,
       filename = "model_2_logodds_concavity_worst.png",
       units = "in",
       bg = "white")
@

<<fig.show='hide', highlight=TRUE, warning=FALSE, message=FALSE, echo=FALSE>>=
linearity_check_df_2 %>%
  ggplot(aes(x = symmetry_worst, y = logodds_2)) +
  geom_point(size = 1, col = "red") +
  geom_smooth(method = "lm", formula = y ~ x) +
  labs(x = "Symmetry Worst", y = "Log Odds", title = "Log-odds ~ symmetry_worst")
@

<<echo=FALSE>>=
ggsave(path = "D:\\Users\\Documents\\sem_6_project\\project_rnw",
       width = 6,
       height = 6,
       device = 'png',
       dpi = 1000,
       filename = "model_2_logodds_symmetry_worst.png",
       units = "in",
       bg = "white")
@

<<fig.show='hide', highlight=TRUE, warning=FALSE, message=FALSE, echo=FALSE>>=
linearity_check_df_2 %>%
  ggplot(aes(x = fractal_dimension_worst, y = logodds_2)) +
  geom_point(size = 1, col = "red") +
  geom_smooth(method = "lm", formula = y ~ x) +
  labs(x = "Fractal Dimension Worst", y = "Log Odds",
       title = "Log-odds ~ fractal_dimension_worst")
@

<<echo=FALSE>>=
ggsave(path = "D:\\Users\\Documents\\sem_6_project\\project_rnw",
       width = 6,
       height = 6,
       device = 'png',
       dpi = 1000,
       filename = "model_2_logodds_fractal_dimension_worst.png",
       units = "in",
       bg = "white")
@

\begin{table}[H]
\caption*{Log-odds vs Predictors of the Model}
\begin{center}
\begin{tabular}{cc}
\includegraphics[scale = 0.5]{model_2_logodds_radius_se} & \includegraphics[scale = 0.5]{model_2_logodds_radius_worst} \\

\includegraphics[scale = 0.5]{model_2_logodds_texture_worst} & \includegraphics[scale = 0.5]{model_2_logodds_smoothness_worst} \\

\includegraphics[scale = 0.5]{model_2_logodds_concavity_worst} & \includegraphics[scale = 0.5]{model_2_logodds_symmetry_worst}
\end{tabular}
\end{center}
\end{table}

\newpage

\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{model_2_logodds_fractal_dimension_worst}
\end{figure}

\subsubsection{\textcolor{col5}{Confusion Matrix and Evaluation Metrics}}

Now we shall run our model on the \textbf{\textit{Test Set}} and evaluate different evaluation metrics.

<<>>=
probs_2 <- predict(fit_sw_1, newdata = test_sw, type = "response")
@

$\bullet$ We use 0.5 as our threshold value.

<<echo=FALSE>>=
preds_2 <- ifelse(probs_2 >= 0.5, "Malignant", "Benign")
outcome_2 <- ifelse(test_sw$diagnosis_encoded == 1, "Malignant", "Benign")
cm_2 <- table(outcome_2, preds_2)
@

<<echo=FALSE>>=
cm_df_2 <- as.data.frame(cm_2)
cm_df_2$type <- c("True Positive", "False Positive", "False Negative", "True Negative")
@

<<echo=FALSE, highlight=TRUE, fig.show='hide'>>=
cm_df_2 %>%
ggplot(aes(y = preds_2, x = outcome_2, fill = Freq)) +
  geom_tile(color = "white") +
  geom_text(aes(label = glue("{type} - {Freq}"))) +
  scale_fill_gradient(low = "#F01181", high = "#49FE00") +
  labs(title = "Confusion Matrix for Model 2",
       x = "Predicted",
       y = "Actual") +
  theme_minimal() +
  scale_x_discrete(labels = c("Benign", "Malignant")) +
  scale_y_discrete(labels = c("Benign", "Malignant")) +
  theme(axis.text.y = element_text(angle = 90, hjust = 0.5),
        legend.position = "none")
@

<<echo=FALSE>>=
ggsave(path = "D:\\Users\\Documents\\sem_6_project\\project_rnw",
       width = 10,
       height = 10,
       device = 'png',
       dpi = 1000,
       filename = "model_2_confusion_matrix.png",
       units = "in",
       bg = "white")
@

\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{model_2_confusion_matrix}
\end{figure}

Different evaluation metrics are given as follows : \\

$\blacktriangleright$ For model 2, \textcolor{col13}{\textbf{\textit{accuracy}}} is \Sexpr{(cm_2[1] + cm_2[4])/(sum(cm_2))}. \\

<<echo=FALSE>>=
recall_2 <- cm_2[1] / (cm_2[1] + cm_2[3])
@

$\blacktriangleright$ For model 2, \textcolor{col13}{\textbf{\textit{recall}}} is \Sexpr{(cm_2[1])/(cm_2[1] + cm_2[3])}. \\

<<echo=FALSE>>=
precision_2 <- cm_2[1] / (cm_2[1] + cm_2[2])
@

$\blacktriangleright$ For model 2, \textcolor{col13}{\textbf{\textit{precision}}} is \Sexpr{(cm_2[1])/(cm_2[1] + cm_2[2])}. \\

$\blacktriangleright$ For model 2, \textcolor{col13}{\textbf{\textit{F1 Score}}} is \Sexpr{(2 * recall_2 * precision_2)/(recall_2 + precision_2)}.





\vspace{0.3cm}

\section{\textcolor{COL1}{The Better Model}}

\subsubsection{\textcolor{col5}{Comparing Deviance Residuals}}

\hspace{1cm} The deviance residual is useful for determining if individual points are not well fit by the model. The deviance residual for $i$-th observation is given by 
$$d_i = \pm \left[ -2 \{ Y_i \log \hat{p_i} + (1 - Y_i) \log (1- \hat{p_i}) \} \right]^{\frac{1}{2}}$$
where the sign is positive when $Y_i \geq \hat{p_i}$ and negative otherwise; \\
\begin{equation*}
        Y_i = \begin{cases}
              1 & \text{if $i$-th observation is \textbf{\textit{\textcolor{col7}{Malignant}}}} \\
              0 & \text{if $i$-th observation is \textbf{\textit{\textcolor{col8}{Benign}}}}
              \end{cases}
\end{equation*}

and $\hat{p_i}$ is the predicted probability for $i$-th observation. \\

The residual deviance statistic for a model is given by $D = \sum\limits_{i}{d_i}^2$. \\

Residual deviance for the model with \textbf{\textit{mean}} and \textbf{\textit{se}} variables is \Sexpr{deviance(fit_ms_1)}. That for the model with \textbf{\textit{se}} and \textbf{\textit{worst}} variables is \Sexpr{deviance(fit_sw_1)}. Clearly, the latter provides a better fit.


\subsubsection{\textcolor{col5}{Comparing Accuracy}}

\hspace{1cm} We compare the two models by their respective accuracies. In order to do so, we train our models on multiple training sets, then run them on the corresponding test sets and note the accuracies. \\

<<echo=FALSE>>=
ms_fits <- list()
ms_predicted_probs <- list()
ms_predictions <- list()
ms_outcomes <- list()
ms_confusion_matrices <- list()

ms_accuracies <- c()

for (i in 1:3) {
  ms_fits[[i]] <- glm(diagnosis_encoded ~ ., data = training_sets_ms[[i]], family = binomial)
  ms_predicted_probs[[i]] <- predict(ms_fits[[i]], newdata = test_sets_ms[[i]], type = "response")
  
  ms_predictions[[i]] <- ifelse(ms_predicted_probs[[i]] >= 0.5, "Malignant", "Benign")
  
  ms_outcomes[[i]] <- ifelse(test_sets_ms[[i]]$diagnosis_encoded == 1, "Malignant", 
"Benign")
  
  ms_confusion_matrices[[i]] <- table(ms_outcomes[[i]], ms_predictions[[i]])
  
  ms_accuracies[i] <- (ms_confusion_matrices[[i]][1] + ms_confusion_matrices[[i]][4])/sum(ms_confusion_matrices[[i]])
  
}

@

$\bullet$ For the model with \textbf{\textit{mean}} and \textbf{\textit{se}} variables, the accuracies are
<<echo=FALSE>>=
print(ms_accuracies)
@


<<echo=FALSE, warning=FALSE, message=FALSE>>=
sw_fits <- list()
sw_predicted_probs <- list()
sw_predictions <- list()
sw_outcomes <- list()
sw_confusion_matrices <- list()

sw_accuracies <- c()

for (i in 1:3) {
  sw_fits[[i]] <- glm(diagnosis_encoded ~ ., data = training_sets_sw[[i]], family = binomial)
  sw_predicted_probs[[i]] <- predict(sw_fits[[i]], newdata = test_sets_sw[[i]], type = "response")
  
  sw_predictions[[i]] <- ifelse(sw_predicted_probs[[i]] >= 0.5, "Malignant", "Benign")
  
  sw_outcomes[[i]] <- ifelse(test_sets_sw[[i]]$diagnosis_encoded == 1, "Malignant", 
"Benign")
  
  sw_confusion_matrices[[i]] <- table(sw_outcomes[[i]], sw_predictions[[i]])
  
  sw_accuracies[i] <- (sw_confusion_matrices[[i]][1] + sw_confusion_matrices[[i]][4])/sum(sw_confusion_matrices[[i]])
  
}

@

$\bullet$ For the model with \textbf{\textit{se}} and \textbf{\textit{worst}} variables, the accuracies are
<<echo=FALSE>>=
print(sw_accuracies)
@


$\blacktriangleright$ Average accuracy of the first model is \Sexpr{mean(ms_accuracies)}, while that of the second model is \Sexpr{mean(sw_accuracies)}. \\

\vspace{0.3cm}

\smallpencil \hspace{0.5cm} The model with \textbf{\textit{se}} and \textbf{\textit{worst}} variables has better performance. We shall use this model for predicting Malignancy.


\vspace{0.8cm}

\begin{center}
\BlackRookOnBlack \BlackKnightOnWhite \BlackBishopOnBlack \BlackKingOnWhite \BlackQueenOnBlack \BlackBishopOnWhite \BlackKnightOnBlack \BlackRookOnWhite
\end{center}



\end{document}